{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3592eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bisect\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from pandas import DataFrame\n",
    "from logging import getLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import bincount\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class InductiveConformalPredictor():\n",
    "    \"\"\"\n",
    "    Standard Conformal Predictor with uncertainty non-conformity score.\n",
    "    Args:\n",
    "        predictor: classifier used in upstream task.\n",
    "\n",
    "    FROM: https://medium.com/data-from-the-trenches/measuring-models-uncertainty-with-conformal-prediction-f6aa8debb50e\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, predictor):\n",
    "        self.predictor = predictor\n",
    "        check_is_fitted(self.predictor, attributes=[\"classes_\"])\n",
    "\n",
    "        self._le = LabelEncoder()\n",
    "        self.classes = self._le.fit_transform(predictor.classes_)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.calibration_score = self._uncertainty_conformity_score(X)\n",
    "        self.calibration_class = self._le.transform(y)\n",
    "        return self\n",
    "\n",
    "    def _uncertainty_conformity_score(self, data):\n",
    "        uncertainty_score = 1 - self.predictor.predict_proba(data)\n",
    "        return uncertainty_score\n",
    "\n",
    "    def predict_proba(self, X, mondrian=True):\n",
    "        check_is_fitted(self, attributes=[\"calibration_score\"])\n",
    "\n",
    "        conformity_score = self._uncertainty_conformity_score(X)\n",
    "        conformal_pred = np.zeros(conformity_score.shape)\n",
    "\n",
    "        for c in self.classes:\n",
    "            if mondrian:\n",
    "                calibration_filt = self.calibration_score[self.calibration_class == c]\n",
    "                calib = calibration_filt[:, c]\n",
    "            else:\n",
    "                calib = self.calibration_score[range(len(self.calibration_class)), \n",
    "                                                          self.calibration_class]\n",
    "\n",
    "            sorted_calib = np.sort(calib)\n",
    "            conformal_pred[:, c] = [float(bisect.bisect(sorted_calib, x))/len(calib)\n",
    "                                    for x in conformity_score[:, c]]\n",
    "\n",
    "        return conformal_pred\n",
    "\n",
    "    def predict(self, X, mondrian=True, alpha=0.05):\n",
    "        _conformal_proba = self.predict_proba(X=X, mondrian=mondrian)\n",
    "        conformal_pred = (_conformal_proba > alpha).astype(int)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        mlb.fit([self._le.classes_])\n",
    "        pred = mlb.inverse_transform(conformal_pred)\n",
    "\n",
    "        return pred\n",
    "\n",
    "ALPHA = 0.25\n",
    "\n",
    "\n",
    "def return_conformity_scores(\n",
    "    data, params, model\n",
    ") -> DataFrame:\n",
    "    cfm = InductiveConformalPredictor(predictor=model)\n",
    "\n",
    "    X, Y = data[params.get('features')], data[params.get('target')]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, test_size=0.20, random_state=42)\n",
    "\n",
    "    cfm.fit(X_train, y_train)\n",
    "\n",
    "    y_test_conf = cfm.predict(X, alpha=ALPHA)\n",
    "\n",
    "    data = data.copy()\n",
    "\n",
    "    data['y_test_conf'] = y_test_conf \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44941f",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = catalog.load('scored_test')\n",
    "model = catalog.load('model')\n",
    "\n",
    "d2 = return_conformity_scores(data_test, context.params, model)\n",
    "\n",
    "cats = d2.y_test_conf.unique()\n",
    "\n",
    "print(\"Random Forest\\n\")\n",
    "for cat in cats:\n",
    "    d = d2[d2.y_test_conf == cat].copy()\n",
    "    print(\"Mean: %4.2f -- Share: %3.1f%% -- Share Target: %3.1f%%\" % (\n",
    "        d.target.mean(), 100*(d.shape[0]/d2.shape[0]), 100*((d.target==1).sum()/(d2.target==1).sum())\n",
    "    ))\n",
    "    print(\"Bincount: %s\" % bincount(d.target))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197bf90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.prob.hist(bins=20)\n",
    "plt.axvline((d2[d2.y_test_conf == (0,1)]).prob.min(), c='r')\n",
    "plt.axvline((d2[d2.y_test_conf == (0,1)]).prob.max(), c='r')\n",
    "plt.title(\"Random Forest Classifier\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"model.predict_proba\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e6cd1",
   "metadata": {},
   "source": [
    "# Catboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = catalog.load('catboost.scored_test')\n",
    "model = catalog.load('catboost.model')\n",
    "\n",
    "d2 = return_conformity_scores(data_test, context.params, model)\n",
    "\n",
    "cats = d2.y_test_conf.unique()\n",
    "\n",
    "print(\"Catboost\\n\")\n",
    "for cat in cats:\n",
    "    d = d2[d2.y_test_conf == cat].copy()\n",
    "    print(\"Mean: %4.2f -- Share: %3.1f%% -- Share Target: %3.1f%%\" % (\n",
    "        d.target.mean(), 100*(d.shape[0]/d2.shape[0]), 100*((d.target==1).sum()/(d2.target==1).sum())\n",
    "    ))\n",
    "    print(\"Bincount: %s\" % bincount(d.target))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.prob.hist(bins=20)\n",
    "plt.axvline((d2[d2.y_test_conf == (0,1)]).prob.min(), c='r')\n",
    "plt.axvline((d2[d2.y_test_conf == (0,1)]).prob.max(), c='r')\n",
    "plt.title(\"Catboost Classifier\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"model.predict_proba\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad676f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KedroClassification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
