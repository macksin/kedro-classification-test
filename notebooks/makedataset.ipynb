{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c80de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-01 17:09:35,328 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
      "2022-01-01 17:09:35,337 - kedro.framework.session.session - WARNING - Unable to git describe /home/mashcon/Documents/Kedro/kedro-classification\n",
      "2022-01-01 17:09:35,348 - root - INFO - ** Kedro project Kedro Classification\n",
      "2022-01-01 17:09:35,354 - root - INFO - Defined global variable `context`, `session`, `catalog` and `pipelines`\n",
      "2022-01-01 17:09:35,367 - root - INFO - Registered line magic `run_viz`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4b77fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4482  518] 0.1036\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.578527</td>\n",
       "      <td>-2.178321</td>\n",
       "      <td>1.377153</td>\n",
       "      <td>-2.178321</td>\n",
       "      <td>-1.083942</td>\n",
       "      <td>3.445078</td>\n",
       "      <td>1.254249</td>\n",
       "      <td>-0.934836</td>\n",
       "      <td>-0.785528</td>\n",
       "      <td>-0.011355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975939</td>\n",
       "      <td>1.292840</td>\n",
       "      <td>4.894074</td>\n",
       "      <td>-0.834173</td>\n",
       "      <td>-8.488700</td>\n",
       "      <td>-0.034934</td>\n",
       "      <td>-1.277238</td>\n",
       "      <td>0.520439</td>\n",
       "      <td>4.974919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.339980</td>\n",
       "      <td>-0.423972</td>\n",
       "      <td>-2.294981</td>\n",
       "      <td>-0.423972</td>\n",
       "      <td>-0.186411</td>\n",
       "      <td>-0.256856</td>\n",
       "      <td>-0.619768</td>\n",
       "      <td>-1.131674</td>\n",
       "      <td>-0.404335</td>\n",
       "      <td>0.463058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142582</td>\n",
       "      <td>1.383969</td>\n",
       "      <td>-0.241896</td>\n",
       "      <td>0.472751</td>\n",
       "      <td>4.974429</td>\n",
       "      <td>-1.499910</td>\n",
       "      <td>0.337041</td>\n",
       "      <td>1.198929</td>\n",
       "      <td>0.219652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.241103</td>\n",
       "      <td>0.940064</td>\n",
       "      <td>-0.169744</td>\n",
       "      <td>0.940064</td>\n",
       "      <td>1.002450</td>\n",
       "      <td>-0.532289</td>\n",
       "      <td>0.043938</td>\n",
       "      <td>-0.539421</td>\n",
       "      <td>-0.845562</td>\n",
       "      <td>0.545535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179683</td>\n",
       "      <td>0.316695</td>\n",
       "      <td>0.350912</td>\n",
       "      <td>1.334609</td>\n",
       "      <td>-3.041916</td>\n",
       "      <td>1.719314</td>\n",
       "      <td>-0.370429</td>\n",
       "      <td>-0.251795</td>\n",
       "      <td>1.764768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.125079</td>\n",
       "      <td>-2.028795</td>\n",
       "      <td>-0.986137</td>\n",
       "      <td>-2.028795</td>\n",
       "      <td>-0.548571</td>\n",
       "      <td>-1.135296</td>\n",
       "      <td>2.478615</td>\n",
       "      <td>-0.627491</td>\n",
       "      <td>-0.774204</td>\n",
       "      <td>-0.869454</td>\n",
       "      <td>...</td>\n",
       "      <td>1.433324</td>\n",
       "      <td>0.538595</td>\n",
       "      <td>0.730390</td>\n",
       "      <td>-0.096968</td>\n",
       "      <td>-2.419251</td>\n",
       "      <td>-0.916072</td>\n",
       "      <td>-0.279173</td>\n",
       "      <td>1.075836</td>\n",
       "      <td>2.083218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.701396</td>\n",
       "      <td>3.276916</td>\n",
       "      <td>0.897996</td>\n",
       "      <td>3.276916</td>\n",
       "      <td>1.654605</td>\n",
       "      <td>-0.511139</td>\n",
       "      <td>0.637480</td>\n",
       "      <td>-1.417502</td>\n",
       "      <td>-0.273468</td>\n",
       "      <td>-1.706435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188478</td>\n",
       "      <td>-0.859873</td>\n",
       "      <td>-3.870387</td>\n",
       "      <td>-0.372196</td>\n",
       "      <td>6.057739</td>\n",
       "      <td>-0.127960</td>\n",
       "      <td>-0.023065</td>\n",
       "      <td>2.159505</td>\n",
       "      <td>-1.675177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-4.301284</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>-0.461950</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>-0.047772</td>\n",
       "      <td>0.705102</td>\n",
       "      <td>0.182830</td>\n",
       "      <td>1.200105</td>\n",
       "      <td>-1.384144</td>\n",
       "      <td>0.028827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460417</td>\n",
       "      <td>-1.313216</td>\n",
       "      <td>0.738808</td>\n",
       "      <td>-0.342607</td>\n",
       "      <td>-2.450401</td>\n",
       "      <td>-1.449423</td>\n",
       "      <td>-1.246834</td>\n",
       "      <td>0.874511</td>\n",
       "      <td>0.535540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-4.734128</td>\n",
       "      <td>4.747508</td>\n",
       "      <td>-1.607681</td>\n",
       "      <td>4.747508</td>\n",
       "      <td>0.061971</td>\n",
       "      <td>1.250541</td>\n",
       "      <td>-0.638886</td>\n",
       "      <td>-0.951743</td>\n",
       "      <td>-0.337015</td>\n",
       "      <td>0.379838</td>\n",
       "      <td>...</td>\n",
       "      <td>1.172254</td>\n",
       "      <td>-0.699319</td>\n",
       "      <td>-1.161398</td>\n",
       "      <td>-2.250756</td>\n",
       "      <td>2.306080</td>\n",
       "      <td>-1.971167</td>\n",
       "      <td>0.714640</td>\n",
       "      <td>0.701056</td>\n",
       "      <td>1.507332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2.934002</td>\n",
       "      <td>-2.275154</td>\n",
       "      <td>0.028919</td>\n",
       "      <td>-2.275154</td>\n",
       "      <td>-0.651679</td>\n",
       "      <td>0.650684</td>\n",
       "      <td>4.068410</td>\n",
       "      <td>0.930393</td>\n",
       "      <td>-1.550773</td>\n",
       "      <td>0.329846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866957</td>\n",
       "      <td>-0.347209</td>\n",
       "      <td>-1.795518</td>\n",
       "      <td>-2.218161</td>\n",
       "      <td>-2.119973</td>\n",
       "      <td>-1.374924</td>\n",
       "      <td>-1.149658</td>\n",
       "      <td>-0.506633</td>\n",
       "      <td>-1.655551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-0.078423</td>\n",
       "      <td>-0.446618</td>\n",
       "      <td>0.335504</td>\n",
       "      <td>-0.446618</td>\n",
       "      <td>0.748840</td>\n",
       "      <td>-0.248997</td>\n",
       "      <td>-0.111572</td>\n",
       "      <td>-1.109129</td>\n",
       "      <td>-0.635568</td>\n",
       "      <td>-0.322627</td>\n",
       "      <td>...</td>\n",
       "      <td>1.548207</td>\n",
       "      <td>0.434992</td>\n",
       "      <td>0.457849</td>\n",
       "      <td>0.563647</td>\n",
       "      <td>-2.749396</td>\n",
       "      <td>-1.542489</td>\n",
       "      <td>-0.539987</td>\n",
       "      <td>-0.974946</td>\n",
       "      <td>1.404619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.367260</td>\n",
       "      <td>-2.123172</td>\n",
       "      <td>2.179015</td>\n",
       "      <td>-2.123172</td>\n",
       "      <td>-0.417638</td>\n",
       "      <td>-0.420314</td>\n",
       "      <td>0.623410</td>\n",
       "      <td>0.630373</td>\n",
       "      <td>-0.482059</td>\n",
       "      <td>0.676910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212795</td>\n",
       "      <td>0.408601</td>\n",
       "      <td>-1.829328</td>\n",
       "      <td>-1.612204</td>\n",
       "      <td>4.892612</td>\n",
       "      <td>-0.549897</td>\n",
       "      <td>-0.595348</td>\n",
       "      <td>1.542717</td>\n",
       "      <td>-1.227677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -7.578527 -2.178321  1.377153 -2.178321 -1.083942  3.445078  1.254249   \n",
       "1    -2.339980 -0.423972 -2.294981 -0.423972 -0.186411 -0.256856 -0.619768   \n",
       "2    -2.241103  0.940064 -0.169744  0.940064  1.002450 -0.532289  0.043938   \n",
       "3    -2.125079 -2.028795 -0.986137 -2.028795 -0.548571 -1.135296  2.478615   \n",
       "4     2.701396  3.276916  0.897996  3.276916  1.654605 -0.511139  0.637480   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4995 -4.301284  0.499270 -0.461950  0.499270 -0.047772  0.705102  0.182830   \n",
       "4996 -4.734128  4.747508 -1.607681  4.747508  0.061971  1.250541 -0.638886   \n",
       "4997  2.934002 -2.275154  0.028919 -2.275154 -0.651679  0.650684  4.068410   \n",
       "4998 -0.078423 -0.446618  0.335504 -0.446618  0.748840 -0.248997 -0.111572   \n",
       "4999  0.367260 -2.123172  2.179015 -2.123172 -0.417638 -0.420314  0.623410   \n",
       "\n",
       "             7         8         9  ...        41        42        43  \\\n",
       "0    -0.934836 -0.785528 -0.011355  ...  0.975939  1.292840  4.894074   \n",
       "1    -1.131674 -0.404335  0.463058  ... -0.142582  1.383969 -0.241896   \n",
       "2    -0.539421 -0.845562  0.545535  ...  0.179683  0.316695  0.350912   \n",
       "3    -0.627491 -0.774204 -0.869454  ...  1.433324  0.538595  0.730390   \n",
       "4    -1.417502 -0.273468 -1.706435  ...  0.188478 -0.859873 -3.870387   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4995  1.200105 -1.384144  0.028827  ...  0.460417 -1.313216  0.738808   \n",
       "4996 -0.951743 -0.337015  0.379838  ...  1.172254 -0.699319 -1.161398   \n",
       "4997  0.930393 -1.550773  0.329846  ...  0.866957 -0.347209 -1.795518   \n",
       "4998 -1.109129 -0.635568 -0.322627  ...  1.548207  0.434992  0.457849   \n",
       "4999  0.630373 -0.482059  0.676910  ... -0.212795  0.408601 -1.829328   \n",
       "\n",
       "            44        45        46        47        48        49  target  \n",
       "0    -0.834173 -8.488700 -0.034934 -1.277238  0.520439  4.974919       0  \n",
       "1     0.472751  4.974429 -1.499910  0.337041  1.198929  0.219652       1  \n",
       "2     1.334609 -3.041916  1.719314 -0.370429 -0.251795  1.764768       0  \n",
       "3    -0.096968 -2.419251 -0.916072 -0.279173  1.075836  2.083218       0  \n",
       "4    -0.372196  6.057739 -0.127960 -0.023065  2.159505 -1.675177       0  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "4995 -0.342607 -2.450401 -1.449423 -1.246834  0.874511  0.535540       0  \n",
       "4996 -2.250756  2.306080 -1.971167  0.714640  0.701056  1.507332       0  \n",
       "4997 -2.218161 -2.119973 -1.374924 -1.149658 -0.506633 -1.655551       0  \n",
       "4998  0.563647 -2.749396 -1.542489 -0.539987 -0.974946  1.404619       1  \n",
       "4999 -1.612204  4.892612 -0.549897 -0.595348  1.542717 -1.227677       0  \n",
       "\n",
       "[5000 rows x 51 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.datasets import make_classification\n",
    "from numpy import bincount, mean\n",
    "\n",
    "args = dict(\n",
    "    n_samples=5_000,\n",
    "    n_features=50,\n",
    "    n_informative=10, \n",
    "    n_redundant=10, \n",
    "    n_repeated=5, \n",
    "    n_classes=2, \n",
    "    n_clusters_per_class=2,\n",
    "    weights=(0.9,),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "data = make_classification(**args)\n",
    "\n",
    "print(bincount(data[1]), mean(data[1]))\n",
    "\n",
    "f = DataFrame(data[0])\n",
    "f['target'] = data[1]\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83a3e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_classification in module sklearn.datasets._samples_generator:\n",
      "\n",
      "make_classification(n_samples=100, n_features=20, *, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
      "    Generate a random n-class classification problem.\n",
      "    \n",
      "    This initially creates clusters of points normally distributed (std=1)\n",
      "    about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
      "    length ``2*class_sep`` and assigns an equal number of clusters to each\n",
      "    class. It introduces interdependence between these features and adds\n",
      "    various types of further noise to the data.\n",
      "    \n",
      "    Without shuffling, ``X`` horizontally stacks features in the following\n",
      "    order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
      "    linear combinations of the informative features, followed by ``n_repeated``\n",
      "    duplicates, drawn randomly with replacement from the informative and\n",
      "    redundant features. The remaining features are filled with random noise.\n",
      "    Thus, without shuffling, all useful features are contained in the columns\n",
      "    ``X[:, :n_informative + n_redundant + n_repeated]``.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <sample_generators>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n_samples : int, default=100\n",
      "        The number of samples.\n",
      "    \n",
      "    n_features : int, default=20\n",
      "        The total number of features. These comprise ``n_informative``\n",
      "        informative features, ``n_redundant`` redundant features,\n",
      "        ``n_repeated`` duplicated features and\n",
      "        ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
      "        drawn at random.\n",
      "    \n",
      "    n_informative : int, default=2\n",
      "        The number of informative features. Each class is composed of a number\n",
      "        of gaussian clusters each located around the vertices of a hypercube\n",
      "        in a subspace of dimension ``n_informative``. For each cluster,\n",
      "        informative features are drawn independently from  N(0, 1) and then\n",
      "        randomly linearly combined within each cluster in order to add\n",
      "        covariance. The clusters are then placed on the vertices of the\n",
      "        hypercube.\n",
      "    \n",
      "    n_redundant : int, default=2\n",
      "        The number of redundant features. These features are generated as\n",
      "        random linear combinations of the informative features.\n",
      "    \n",
      "    n_repeated : int, default=0\n",
      "        The number of duplicated features, drawn randomly from the informative\n",
      "        and the redundant features.\n",
      "    \n",
      "    n_classes : int, default=2\n",
      "        The number of classes (or labels) of the classification problem.\n",
      "    \n",
      "    n_clusters_per_class : int, default=2\n",
      "        The number of clusters per class.\n",
      "    \n",
      "    weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
      "        The proportions of samples assigned to each class. If None, then\n",
      "        classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
      "        then the last class weight is automatically inferred.\n",
      "        More than ``n_samples`` samples may be returned if the sum of\n",
      "        ``weights`` exceeds 1. Note that the actual class proportions will\n",
      "        not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
      "    \n",
      "    flip_y : float, default=0.01\n",
      "        The fraction of samples whose class is assigned randomly. Larger\n",
      "        values introduce noise in the labels and make the classification\n",
      "        task harder. Note that the default setting flip_y > 0 might lead\n",
      "        to less than ``n_classes`` in y in some cases.\n",
      "    \n",
      "    class_sep : float, default=1.0\n",
      "        The factor multiplying the hypercube size.  Larger values spread\n",
      "        out the clusters/classes and make the classification task easier.\n",
      "    \n",
      "    hypercube : bool, default=True\n",
      "        If True, the clusters are put on the vertices of a hypercube. If\n",
      "        False, the clusters are put on the vertices of a random polytope.\n",
      "    \n",
      "    shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
      "        Shift features by the specified value. If None, then features\n",
      "        are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "    \n",
      "    scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
      "        Multiply features by the specified value. If None, then features\n",
      "        are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "        happens after shifting.\n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Shuffle the samples and the features.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Determines random number generation for dataset creation. Pass an int\n",
      "        for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X : ndarray of shape (n_samples, n_features)\n",
      "        The generated samples.\n",
      "    \n",
      "    y : ndarray of shape (n_samples,)\n",
      "        The integer labels for class membership of each sample.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "    the \"Madelon\" dataset.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "           selection benchmark\", 2003.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    make_blobs : Simplified variant.\n",
      "    make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe15e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KedroClassification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
